{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.sparse import dok_matrix, vstack, csr_matrix\n",
    "from scipy.sparse import dok_matrix, vstack, csr_matrix\n",
    "from snorkel.labeling import PandasLFApplier, LFApplier, LFAnalysis, labeling_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "iob_tags = []\n",
    "text = \"\"\n",
    "filename = './re3d/train.txt'\n",
    "write_filename = \"./re3d/sentences.txt\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    lst = []\n",
    "    while True:\n",
    "        word_lst = file.readline().lower().split(\"\\t\")\n",
    "        word = word_lst[0]\n",
    "        if not word:\n",
    "            break\n",
    "        text += \" \" + word\n",
    "\n",
    "        if word == '\\n':\n",
    "            sents.append(lst)\n",
    "            lst = []\n",
    "        else:\n",
    "            lst.append(word)\n",
    "            iob_tags.append(word_lst[-1].split('\\n')[0])\n",
    "\n",
    "    sents.append(lst)\n",
    "\n",
    "with open(write_filename, 'w') as f:\n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinct Types of IOB Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i-weapon', 'b-documentreference', 'i-militaryplatform', 'b-militaryplatform', 'b-weapon', 'b-money', 'b-temporal', 'i-location', 'b-nationality', 'b-organisation', 'i-temporal', 'o', 'i-quantity', 'b-quantity', 'i-person', 'i-money', 'i-organisation', 'i-documentreference', 'b-person', 'i-nationality', 'b-location'}\n"
     ]
    }
   ],
   "source": [
    "dist = set()\n",
    "for tok in iob_tags:\n",
    "    dist.add(tok)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iob tags are:  20030\n",
      "Number of tokens are:  20030\n"
     ]
    }
   ],
   "source": [
    "# Here we are checking and ensuring that both number of tokens in sentences and number of tags in iob_tags are same\n",
    "print('Number of iob tags are: ',len(iob_tags))\n",
    "\n",
    "l=0\n",
    "for i in range(len(sents)):\n",
    "    l+=len(sents[i])\n",
    "\n",
    "print('Number of tokens are: ',l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting iob tags to numerical tags\n",
    "o = 0\n",
    "b_org = 1\n",
    "i_org = 2\n",
    "b_quan = 3\n",
    "i_quan = 4\n",
    "b_weapon = 5\n",
    "i_weapon = 6\n",
    "b_doc = 7\n",
    "i_doc = 8\n",
    "b_person = 9\n",
    "i_person = 10\n",
    "b_nationality = 11\n",
    "i_nationality = 12\n",
    "b_money = 13\n",
    "i_money = 14\n",
    "b_temporal = 15\n",
    "i_temporal = 16\n",
    "b_loc = 17\n",
    "i_loc = 18\n",
    "b_milplat = 19\n",
    "i_milplat = 20\n",
    "\n",
    "iob_dict = {\n",
    "    \"o\" : 0,\n",
    "    \"b_org\" : 1,\n",
    "    \"i_org\" : 2,\n",
    "    \"b_quan\" : 3,\n",
    "    \"i_quan\" : 4,\n",
    "    \"b_weapon\" : 5,\n",
    "    \"i_weapon\" : 6,\n",
    "    \"b_doc\" : 7,\n",
    "    \"i_doc\" : 8,\n",
    "    \"b_person\" : 9,\n",
    "    \"i_person\" : 10,\n",
    "    \"b_nationality\" : 11,\n",
    "    \"i_nationality\" : 12,\n",
    "    \"b_money\" : 13,\n",
    "    \"i_money\" : 14,\n",
    "    \"b_temporal\" : 15,\n",
    "    \"i_temporal\" : 16,\n",
    "    \"b_loc\" : 17,\n",
    "    \"i_loc\" : 18,\n",
    "    \"b_milplat\" : 19,\n",
    "    \"i_milplat\" : 20,\n",
    "}\n",
    "\n",
    "num_iob_tags = []\n",
    "for tok in iob_tags:\n",
    "    num_iob_tags.append(iob_dict[tok])\n",
    "\n",
    "num_iob_tags = np.array(num_iob_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def dict_match(sentence, dictionary, max_ngrams=4):\n",
    "   m = {}\n",
    "   for i in range(len(sentence)):\n",
    "       for j in range(i+1, min(len(sentence), i + max_ngrams) + 1):\n",
    "           term = ' '.join(sentence[i:j])\n",
    "           if term in dictionary:\n",
    "               m.update({idx:1 for idx in range(i,j+1)})\n",
    "   return m\n",
    "           \n",
    "         \n",
    "def create_token_L_mat(Xs, Ls, num_lfs):\n",
    "   \"\"\"\n",
    "   Create token-level LF matrix from LFs indexed by sentence\n",
    "   \"\"\"\n",
    "   Yws = []\n",
    "   for sent_i in range(len(Xs)):\n",
    "       ys = dok_matrix((len(Xs[sent_i]), num_lfs))\n",
    "       for lf_i in range(num_lfs):\n",
    "           for word_i,y in Ls[sent_i][lf_i].items():\n",
    "               ys[word_i, lf_i] = y\n",
    "       Yws.append(ys)\n",
    "   return csr_matrix(vstack(Yws))\n",
    "\n",
    "\n",
    "  \n",
    "# labeling functions\n",
    "def moneyLF(x):\n",
    "   i_lst = ['dinar','dinars','dollars','million','millions','donor','jordanian','billion','billions']\n",
    "   b_lst = ['$','Â£','wage','wages','salaries','money']\n",
    "\n",
    "   sent_dict = {}\n",
    "   for i in range(len(x)):\n",
    "      if x[i] in i_lst:\n",
    "         sent_dict[i] = i_money\n",
    "      if x[i] in b_lst:\n",
    "         sent_dict[i] = b_money\n",
    "\n",
    "   for i in range(len(x)):\n",
    "      if i+1< len(x) and sent_dict.get(i) != None and sent_dict[i] == b_money and sent_dict.get(i+1)==None:\n",
    "         sent_dict[i+1] = i_money\n",
    "\n",
    "      if i-1 >=0 and sent_dict.get(i) != None and sent_dict[i] == i_money and sent_dict.get(i-1)==None:\n",
    "         sent_dict[i-1] = b_money  \n",
    "\n",
    "   return sent_dict      \n",
    "\n",
    "\n",
    "\n",
    "def quantityLF(x):\n",
    "   i_lst = ['percent','miles','domains','million','millions','thousand','thousands','km','kms','mi','square','squares','m3','acre','acres','%','beds','plus','kilometers','kilometer']\n",
    "\n",
    "   sent_dict = {}\n",
    "   for i in range(len(x)):\n",
    "      if x[i] in i_lst:\n",
    "         sent_dict[i] = i_quan\n",
    "\n",
    "   for i in range(len(x)):\n",
    "      if i-1 >=0 and sent_dict.get(i) != None and sent_dict[i] == i_quan and sent_dict.get(i-1)==None:\n",
    "         sent_dict[i-1] = b_quan \n",
    "\n",
    "   return sent_dict \n",
    "\n",
    "# document reference LF\n",
    "def docLF(x):\n",
    "   i_lst = ['book','books','chapter','resolution','text','texts','report','reports']\n",
    "   b_lst = ['constitution','un','united nation','united nations','executive','executives']\n",
    "\n",
    "   sent_dict = {}\n",
    "   for i in range(len(x)):\n",
    "      if x[i] in i_lst:\n",
    "         sent_dict[i] = i_doc\n",
    "      if x[i] in b_lst:\n",
    "         sent_dict[i] = b_doc\n",
    "\n",
    "   for i in range(len(x)):\n",
    "      if i+1< len(x) and sent_dict.get(i) != None and sent_dict[i] == b_doc and sent_dict.get(i+1)==None:\n",
    "         sent_dict[i+1] = i_doc\n",
    "\n",
    "      if i-1 >=0 and sent_dict.get(i) != None and sent_dict[i] == i_doc and sent_dict.get(i-1)==None:\n",
    "         sent_dict[i-1] = b_doc \n",
    "\n",
    "   return sent_dict      \n",
    "\n",
    "def locLF(x):\n",
    "   b_lst = ['in', 'near', 'above', 'over', 'by', 'along', 'around']\n",
    "\n",
    "   sent_dict = {}\n",
    "   for i in range(len(x)):\n",
    "      if x[i] in b_lst:\n",
    "         sent_dict[i] = b_loc\n",
    "         if i+1<len(x):\n",
    "            sent_dict[i+1] = i_loc\n",
    "\n",
    "   return sent_dict\n",
    "\n",
    "def keywordMatching(s, words_list, iTAG, bTAG):\n",
    "   new_list = []\n",
    "   label_dict = dict()\n",
    "   for word in words_list:\n",
    "      new_list.append(word.lower())\n",
    "   tokens = s.lower()\n",
    "   for i, word in enumerate(tokens):\n",
    "      if word in new_list:\n",
    "         if i > 0 and label_dict[i-1] == iTAG:\n",
    "               label_dict[i] = iTAG\n",
    "         else:\n",
    "               label_dict[i] = bTAG\n",
    "   return label_dict\n",
    "\n",
    "def weaponLF(s):\n",
    "   label_dict = dict()\n",
    "   weapon_words_list = ['weapons','strikes','chemical','rocket','artillery','munitions','strike','VBIED','gun','mortar','propelled','heavy',\n",
    "                            'machine','VBIEDs','bombs','grenade','missile','bomb','barrel','launcher','front','end','weapon','systems','IED']\n",
    "   keywordMatching(s, weapon_words_list, i_weapon, b_weapon)\n",
    "\n",
    "\n",
    "def nationalityLF(s):\n",
    "   label_dict = dict()\n",
    "   nationality_words_list =['Syrian','Iraqi','Kurdish','Yazidi','Arabic','Australian','Shia','Arab',\n",
    "                        'Islam','Shiite','German','Jordan','Israeli','Muslims','Yazidis','Kurmanji','Northern']\n",
    "   keywordMatching(s, nationality_words_list, i_nationality, b_nationality)\n",
    "\n",
    "def orgLF(s):\n",
    "   org_words_list = ['forces', 'Iraq', 'Syrian', 'Coalition', 'United', 'people', 'Iraqi', 'group', 'government', 'regime', 'tactical', 'Forces', 'States', 'Government', 'international', 'Security', 'coalition', 'partners', 'Council', 'UN', 'ISIL', 'military', 'fighters', 'State', 'Department', 'units', 'UK', 'esh', 'community', 'U.S.', 'Command', 'civilians', 'security', 'parties', 'members', 'Force', 'unit', 'SDF', 'terrorist', 'victims', 'officials', 'Arab', 'terrorists', 'leaders', 'Central', 'residents', 'Levant', 'allies', 'Democratic', 'opposition', 'Army', 'families', 'Assad', 'family', 'two', 'Asad', 'Iraqis', 'Islamic', 'Joint', 'Union', 'Qaida', 'Nations', 'Syria', 'Group', 'Members', 'Air', 'Battalion', 'officers', 'organization', 'Marines', 'enemy', 'Task', 'EU', 'women', 'nations', 'friends', 'European', 'Syrians', 'countries']\n",
    "   return keywordMatching(s, org_words_list, i_org, b_org)  \n",
    "\n",
    "def temporalLF(s):\n",
    "   temporal_words_list = ['year', 'hours', 'days', 'December', 'years', '2006', 'week', '2016', 'November', 'past', 'last', 'day', 'months', 'Thanksgiving', 'Dec.', '15', '13', 'weeks', '2005', 'ago', 'Day', 'night', '26', 'end', '27', 'February', '2015', 'four', 'morning', '6', '10', '19', 'following', '2007', '7', 'festive', 'just', 'before', 'Muslim', 'Eid', 'celebration', '14th', 'later', '3', 'Z', 'Time', '2008', 'Sunday', 'May', '88', '91', 'first', 'long', '1979', 'January', 'eve', 'a', 'New', 'Year', '2013', 'month', 'a.m.', '29', '5', '1', '16', '18', 'coming', 'and', '2014', 'two', 'March', 'three', 'attack', 'minutes', 'June', 'from', 'late', 'to', 'early', 'evening', 'September', '20', 'plus', '6th', '7th', '25', '2011', 'summer', '2017', 'on', 'Thursday', '28', 'July', '2009', 'weekend', 'August', 'in', 'or', 'seven']\n",
    "   return keywordMatching(s, temporal_words_list, i_temporal, b_temporal)   \n",
    "\n",
    "lfs = [\n",
    "   moneyLF,\n",
    "   quantityLF,\n",
    "   locLF,\n",
    "   nationalityLF,\n",
    "   weaponLF,\n",
    "   docLF,\n",
    "   orgLF,\n",
    "   temporalLF\n",
    "]\n",
    "\n",
    "# apply labeling functions and transform label matrix \n",
    "L = [[lf(s) for lf in lfs] for s in sents] \n",
    "\n",
    "L = create_token_L_mat(sents, L, len(lfs))  \n",
    "L = np.asarray(L.astype(np.int8).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=4, verbose=True)\n",
    "label_model.fit(L_train=L, n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "label_model.predict(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding accuracy\n",
    "label_model_acc = label_model.score(L=L, Y=num_iob_tags, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(label_model_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05846dba5a63881521995e4873c40bc366d65f96d65e5e13c55171c3c8697e3d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.cv0env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
