{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sents = []\n",
    "iob_tags = []\n",
    "text = \"\"\n",
    "filename = \"./re3d/train.txt\"\n",
    "# filename = './conll2003/small_data.txt'\n",
    "with open(filename, 'r') as file:\n",
    "    lst = []\n",
    "    while True:\n",
    "        word_lst = file.readline().lower().split('\\t')\n",
    "        word = word_lst[0]\n",
    "        if not word:\n",
    "            break\n",
    "        text += \" \" + word\n",
    "\n",
    "        if word == '\\n':\n",
    "            sents.append(lst)\n",
    "            lst = []\n",
    "        else:\n",
    "            lst.append(word)\n",
    "            iob_tags.append(word_lst[-1].split('\\n')[0])\n",
    "\n",
    "    sents.append(lst)\n",
    "\n",
    "with open('./re3d/sentences.txt', 'w') as f:\n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinct Types of IOB Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i-weapon', 'b-documentreference', 'i-militaryplatform', 'b-militaryplatform', 'b-weapon', 'b-money', 'b-temporal', 'i-location', 'b-nationality', 'b-organisation', 'i-temporal', 'o', 'i-quantity', 'b-quantity', 'i-person', 'i-money', 'i-organisation', 'i-documentreference', 'b-person', 'i-nationality', 'b-location'}\n"
     ]
    }
   ],
   "source": [
    "dist = set()\n",
    "for tok in iob_tags:\n",
    "    dist.add(tok)\n",
    "\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iob tags are:  20030\n",
      "Number of tokens are:  20030\n"
     ]
    }
   ],
   "source": [
    "# Here we are checking and ensuring that both number of tokens in sentences and number of tags in iob_tags are same\n",
    "print('Number of iob tags are: ',len(iob_tags))\n",
    "\n",
    "l=0\n",
    "for i in range(len(sents)):\n",
    "    l+=len(sents[i])\n",
    "\n",
    "print('Number of tokens are: ',l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting iob tags to numerical tags\n",
    "o = 0\n",
    "b_org = 1\n",
    "i_org = 2\n",
    "b_per = 3\n",
    "i_per = 4\n",
    "b_loc = 5\n",
    "i_loc = 6\n",
    "b_misc = 7\n",
    "i_misc = 8\n",
    "\n",
    "iob_dict = {'o': 0, 'b-org' : 1, 'i-org' : 2, 'b-per' : 3, 'i-per' : 4, 'b-loc' : 5, 'i-loc' : 6, 'b-misc' : 7, 'i-misc' : 8}\n",
    "\n",
    "num_iob_tags = []\n",
    "for tok in iob_tags:\n",
    "    num_iob_tags.append(iob_dict[tok])\n",
    "\n",
    "num_iob_tags = np.array(num_iob_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix, vstack, csr_matrix\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def dict_match(sentence, dictionary, max_ngrams=4):\n",
    "   m = {}\n",
    "   for i in range(len(sentence)):\n",
    "       for j in range(i+1, min(len(sentence), i + max_ngrams) + 1):\n",
    "           term = ' '.join(sentence[i:j])\n",
    "           if term in dictionary:\n",
    "               m.update({idx:1 for idx in range(i,j+1)})\n",
    "   return m\n",
    "           \n",
    "         \n",
    "def create_token_L_mat(Xs, Ls, num_lfs):\n",
    "   \"\"\"\n",
    "   Create token-level LF matrix from LFs indexed by sentence\n",
    "   \"\"\"\n",
    "   Yws = []\n",
    "   for sent_i in range(len(Xs)):\n",
    "       ys = dok_matrix((len(Xs[sent_i]), num_lfs))\n",
    "       for lf_i in range(num_lfs):\n",
    "           for word_i,y in Ls[sent_i][lf_i].items():\n",
    "               ys[word_i, lf_i] = y\n",
    "       Yws.append(ys)\n",
    "   return csr_matrix(vstack(Yws))\n",
    "\n",
    "\n",
    "  \n",
    "# labeling functions\n",
    "def LF_is_org(s):\n",
    "   dict = {}\n",
    "   if s[0]== 'the' and len(s)>2:\n",
    "      dict[1] = b_org\n",
    "\n",
    "   return dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LF_is_per(s):\n",
    "   dict = {}\n",
    "   # for i in range(len(s)):\n",
    "   #    p = random.random()\n",
    "   #    if p<=0.5:\n",
    "   #       dict[i] = B_PER\n",
    "   return dict\n",
    "\n",
    "\n",
    "\n",
    "def LF_is_loc(s):\n",
    "   dict = {}\n",
    "   # for i in range(len(s)):\n",
    "   #    p = random.random()\n",
    "   #    if p>=0.5:\n",
    "   #       dict[i] = I_ORG\n",
    "   return dict\n",
    "\n",
    "\n",
    "\n",
    "lfs = [\n",
    "   LF_is_org,\n",
    "   LF_is_per,\n",
    "   LF_is_loc\n",
    "]\n",
    "\n",
    "# apply labeling functions and transform label matrix \n",
    "L = [[lf(s) for lf in lfs] for s in sents] \n",
    "\n",
    "L = create_token_L_mat(sents, L, len(lfs))  \n",
    "L = np.asarray(L.astype(np.int8).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=6.647]\n",
      " 10%|█         | 51/500 [00:00<00:00, 502.66epoch/s]INFO:root:[100 epochs]: TRAIN:[loss=0.018]\n",
      " 32%|███▏      | 159/500 [00:00<00:00, 515.16epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.006]\n",
      " 54%|█████▍    | 272/500 [00:00<00:00, 543.66epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.003]\n",
      " 77%|███████▋  | 384/500 [00:00<00:00, 538.86epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.002]\n",
      "100%|██████████| 500/500 [00:00<00:00, 515.85epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=4, verbose=True)\n",
    "label_model.fit(L_train=L, n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "label_model.predict(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8452830188679246\n"
     ]
    }
   ],
   "source": [
    "# finding accuracy\n",
    "label_model_acc = label_model.score(L=L, Y=num_iob_tags, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(label_model_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05846dba5a63881521995e4873c40bc366d65f96d65e5e13c55171c3c8697e3d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.cv0env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
