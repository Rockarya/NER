{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n\n# Latin1 encodes less than 256 characters.\ndata = pd.read_csv(\"../input/entity-annotated-corpus/ner_dataset.csv\", encoding=\"latin1\")\ndata = data.drop(['POS'], axis =1)\n\n# gives ids(1-based) to sentences and removes the Nan \ndata = data.fillna(method=\"ffill\")\ndata.tail(12)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:45:55.777512Z","iopub.execute_input":"2022-04-22T10:45:55.778028Z","iopub.status.idle":"2022-04-22T10:45:56.654216Z","shell.execute_reply.started":"2022-04-22T10:45:55.777979Z","shell.execute_reply":"2022-04-22T10:45:56.653429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = set(list(data['Word'].values))\nwords.add('PADword')\nn_words = len(words)\nn_words","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:34:55.840953Z","iopub.execute_input":"2022-04-22T10:34:55.841537Z","iopub.status.idle":"2022-04-22T10:34:55.93306Z","shell.execute_reply.started":"2022-04-22T10:34:55.841502Z","shell.execute_reply":"2022-04-22T10:34:55.932119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# IOB tags: Inside, Outisde, Beginning\n# org: organization\n# gpe: geopolitical entity\n# eve: event\n# tim: time\n# per: person\n# art: geographic location\n# nat: Mostly for natural thing(not completely sure though)\ntags = list(set(data[\"Tag\"].values))\nn_tags = len(tags)\nprint(n_tags)\nprint(tags)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:46:14.165444Z","iopub.execute_input":"2022-04-22T10:46:14.165817Z","iopub.status.idle":"2022-04-22T10:46:14.212198Z","shell.execute_reply.started":"2022-04-22T10:46:14.165779Z","shell.execute_reply":"2022-04-22T10:46:14.211326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# different POS tags\ntags = list(set(data[\"POS\"].values))\nn_tags = len(tags)\nprint(n_tags)\nprint(tags)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T10:44:33.995588Z","iopub.execute_input":"2022-04-22T10:44:33.995884Z","iopub.status.idle":"2022-04-22T10:44:34.055618Z","shell.execute_reply.started":"2022-04-22T10:44:33.995849Z","shell.execute_reply":"2022-04-22T10:44:34.054332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentenceGetter(object):\n    \n    def __init__(self, data):\n        self.n_sent = 1\n        self.data = data\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n    \n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getter = SentenceGetter(data)\nsent = getter.get_next()\nprint(sent)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = getter.sentences\nprint(len(sentences))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"largest_sen = max(len(sen) for sen in sentences)\nprint('biggest sentence has {} words'.format(largest_sen))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nplt.hist([len(sen) for sen in sentences], bins= 50)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words2index = {w:i for i,w in enumerate(words)}\ntags2index = {t:i for i,t in enumerate(tags)}\nprint(words2index['London'])\nprint(tags2index['B-geo'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 50\nX = [[w[0]for w in s] for s in sentences]\nnew_X = []\nfor seq in X:\n    new_seq = []\n    for i in range(max_len):\n        try:\n            new_seq.append(seq[i])\n        except:\n            new_seq.append(\"PADword\")\n    new_X.append(new_seq)\nnew_X[15]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\ny = [[tags2index[w[1]] for w in s] for s in sentences]\ny = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\ny[15]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.1, random_state=2018)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom keras import backend as K\nsess = tf.Session()\nK.set_session(sess)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\nsess.run(tf.global_variables_initializer())\nsess.run(tf.tables_initializer())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ElmoEmbedding(x):\n    return elmo_model(inputs={\n                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n                            \"sequence_len\": tf.constant(batch_size*[max_len])\n                      },\n                      signature=\"tokens\",\n                      as_dict=True)[\"elmo\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model, Input\nfrom keras.layers.merge import add\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = Input(shape=(max_len,), dtype=tf.string)\nembedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\nx = Bidirectional(LSTM(units=512, return_sequences=True,\n                       recurrent_dropout=0.2, dropout=0.2))(embedding)\nx_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n                           recurrent_dropout=0.2, dropout=0.2))(x)\nx = add([x, x_rnn])  # residual connection to the first biLSTM\nout = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(input_text, out)\nmodel.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\ny_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\ny_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\ny_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),\n                    batch_size=batch_size, epochs=3, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\nX_te = X_te[:149*batch_size]\ntest_pred = model.predict(np.array(X_te), verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx2tag = {i: w for w, i in tags2index.items()}\n\ndef pred2label(pred):\n    out = []\n    for pred_i in pred:\n        out_i = []\n        for p in pred_i:\n            p_i = np.argmax(p)\n            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n        out.append(out_i)\n    return out\n\ndef test2label(pred):\n    out = []\n    for pred_i in pred:\n        out_i = []\n        for p in pred_i:\n            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n        out.append(out_i)\n    return out\n    \npred_labels = pred2label(test_pred)\ntest_labels = test2label(y_te[:149*32])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_labels, pred_labels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 390\np = model.predict(np.array(X_te[i:i+batch_size]))[0]\np = np.argmax(p, axis=-1)\nprint(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\nprint(\"=\"*30)\nfor w, true, pred in zip(X_te[i], y_te[i], p):\n    if w != \"PADword\":\n        print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}